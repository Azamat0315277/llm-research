{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Research (STORM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`STORM` is a research assistant designed by Shao, et. al that extends the idea of \"outline-driven RAG\" for richer article generation.  \n",
    "STORM is designed to generate Wikipedia-style ariticles on a user-provided topic. It applies two main insights to produce more organized and comprehensive articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_community langchain_openai langchain_fireworks langgraph wikipedia duckduckgo-search tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "fast_llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "long_context_llm = ChatOpenAI(model_name=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        \n",
    "     (\n",
    "        \"system\",\n",
    "        \"You are a Wikipedia writer. Write an outline for a Wikipedia page about a user-provided topic. Be comprehensive and specific.\",\n",
    "     ),\n",
    "     (\"user\", \"{topic}\"),   \n",
    "    ]\n",
    ")\n",
    "class Subsection(BaseModel):\n",
    "    subsection_title: str = Field(..., title='Title of the subsection')\n",
    "    description: str = Field(..., title=\"Content of the subsection\")\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f'###{self.subsection_title}\\n\\n{self.description}'.strip()\n",
    "    \n",
    "class Section(BaseModel):\n",
    "    section_title: str = Field(..., title='Title of the section')\n",
    "    description: str = Field(..., title=\"Content of the section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title='Titles and descriptions for each subsection of the Wikipeida page.'\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            f\"###{subsection.subsection_title}\\n\\n{subsection.description}\"\n",
    "            for subsection in self.subsections or []\n",
    "        )\n",
    "        return f\"##{self.section_title}\\n\\n{self.description}\\n\\n{subsections}\".strip()\n",
    "    \n",
    "class Outline(BaseModel):\n",
    "    page_title: str = Field(..., title='Title of the Wikipedia page')\n",
    "    sections: List[Section] = Field(\n",
    "        default_factory=list,\n",
    "        title='Titles and descriptions for each section of the Wikipedia page.',\n",
    "    )\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        sections = \"\\n\\n\".join(section.as_str for section in self.sections)\n",
    "        return f\"# {self.page_title}\\n\\n{sections}\".strip()\n",
    "    \n",
    "generate_outline_direct = direct_gen_outline_prompt | fast_llm.with_structured_output(Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Kazakh Language Large Language Model (LLM) Development\n",
      "\n",
      "##Introduction\n",
      "\n",
      "An overview of what Large Language Models (LLMs) are and their significance in language processing. This section will introduce the concept of developing LLMs specifically tailored for the Kazakh language, addressing the need for better language representation and processing in AI.\n",
      "\n",
      "###What is a Large Language Model?\n",
      "\n",
      "Definition and characteristics of LLMs, with examples of popular models like GPT, BERT, and others.\n",
      "\n",
      "###Importance of Kazakh Language Processing\n",
      "\n",
      "Discuss the growing need for AI tools in minority languages, specifically the Kazakh language, in education, government, and cultural preservation.\n",
      "\n",
      "##Challenges in Kazakh Language LLM Development\n",
      "\n",
      "A detailed exploration of the unique challenges faced when creating an LLM for the Kazakh language.\n",
      "\n",
      "###Linguistic Diversity and Complexity\n",
      "\n",
      "Overview of the grammatical structure, vocabulary, and dialects of Kazakh that complicate LLM training.\n",
      "\n",
      "###Data Availability and Quality\n",
      "\n",
      "Description of the scarcity of high-quality datasets in Kazakh, which poses difficulties for training effective LLMs.\n",
      "\n",
      "###Technological Limitations\n",
      "\n",
      "Discussion on technological constraints, including computational resources necessary for training expansive LLMs.\n",
      "\n",
      "##Data Collection and Preparation\n",
      "\n",
      "Methods and strategies used for gathering and preparing the datasets required for training Kazakh LLMs.\n",
      "\n",
      "###Corpus Development\n",
      "\n",
      "Steps involved in assembling a corpus, including text scraping, cleaning, and validation processes.\n",
      "\n",
      "###Annotation Practices\n",
      "\n",
      "Techniques used to annotate data in terms of grammar, context, and relevance to improve model training.\n",
      "\n",
      "###Collaboration with Local Linguists\n",
      "\n",
      "Importance of partnering with Kazakh linguists to ensure linguistic accuracy and cultural relevance.\n",
      "\n",
      "##Training Approaches\n",
      "\n",
      "Explore the methodologies employed to train Kazakh-specific LLMs.\n",
      "\n",
      "###Model Architecture\n",
      "\n",
      "Discussion on the choice of model architecture, leveraging existing frameworks (e.g., transformer-based models) to suit Kazakh.\n",
      "\n",
      "###Transfer Learning\n",
      "\n",
      "Utilization of transfer learning techniques to enhance the model's performance using data from related languages.\n",
      "\n",
      "###Evaluation Metrics\n",
      "\n",
      "Criteria and benchmarks for evaluating the performance of Kazakh LLMs.\n",
      "\n",
      "##Applications of Kazakh Language LLMs\n",
      "\n",
      "An investigation into the potential applications of Kazakh LLMs across various sectors.\n",
      "\n",
      "###Educational Tools\n",
      "\n",
      "The use of LLMs in developing language learning resources and tools that facilitate education in Kazakh.\n",
      "\n",
      "###Content Creation\n",
      "\n",
      "How LLMs can aid in generating articles, essays, and creative works in Kazakh.\n",
      "\n",
      "###Chatbots and Customer Service\n",
      "\n",
      "Potential applications in building chatbots for customer support and services in the Kazakh language.\n",
      "\n",
      "##Future Directions\n",
      "\n",
      "Speculation and plans regarding the future of Kazakh language LLMs and ongoing research.\n",
      "\n",
      "###Continued Research and Development\n",
      "\n",
      "The importance of ongoing development and research initiatives to improve Kazakh LLMs.\n",
      "\n",
      "###Integration with Other Technologies\n",
      "\n",
      "Exploring how Kazakh LLMs can interface with other AI technologies like speech recognition and translation services.\n",
      "\n",
      "###Community Engagement and Feedback\n",
      "\n",
      "The role of community engagement in the evolution and refinement of Kazakh LLM applications.\n"
     ]
    }
   ],
   "source": [
    "example_topic = \"Creating LLM which can generate answers in Kazakh language\"\n",
    "\n",
    "initial_outline = generate_outline_direct.invoke({\"topic\": example_topic})\n",
    "print(initial_outline.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_related_topics_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"I'm writing a Wikipedia page for a topic mentioned below. \\\n",
    "    Please identify and recommend some Wikipedia pages on closely related subjects. \\\n",
    "    I'm looking for examples that provide insights into interesting aspects commonly associated with this topic, \\\n",
    "    or examples that help me understand the typical content and structure included in Wikipedia pages for similar topics. \\\n",
    "    Please list the as many subjects and urls as you can.   \\\n",
    "    Topic of interest: {topic}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "class RelatedSubjects(BaseModel):\n",
    "    topics: List[str] = Field(\n",
    "        description=\"Comprehensive list of related subjects as background research.\",\n",
    "    )\n",
    "\n",
    "expand_chain = gen_related_topics_prompt | fast_llm.with_structured_output(RelatedSubjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_subjects = await expand_chain.ainvoke({\"topic\": example_topic})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Editor(BaseModel):\n",
    "    affilation: str = Field(\n",
    "        description=\"Primary affilation of the editor.\",\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"Name of the editor.\",\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"Role of the editor in the context of the topic.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Description of the editor's focus, concerns, and motives.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffilation: {self.affilation}\\nDescription: {self.description}\\n\"\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    editors: List[Editor]= Field(\n",
    "        description=\"Comprehensive list of editors with their roles and affiliations.\",\n",
    "        # Add a pydantic validation/restriction to be at most M editors\n",
    "    )\n",
    "gen_perspectives_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You need to select a diverse (and distinct) group of Wikipedia editors who will work together to create a comprehensive article on the topic.\\\n",
    "                Each of them represents a different perspective, role, or affiliation related to this topic.\\\n",
    "            You can use other Wikipedia pages of related topics for inspiration. For each editor, add a description of what they will focus on.\\\n",
    "            Wiki page outlines of related topics for inspiration: {examples}\"\"\",\n",
    "        ),\n",
    "        (\"user\", \"Topic of interest: {topic}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_perspectives_chain = gen_perspectives_prompt | ChatOpenAI(model_name=\"gpt-4o-mini\").with_structured_output(Perspectives)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables import chain as as_runnable\n",
    "\n",
    "wikipedia_retriever = WikipediaRetriever(load_all_available_meta=True, top_k_results=1)\n",
    "\n",
    "def format_doc(doc, max_length=1000):\n",
    "    related = \"- \".join(doc.metadata['categories'])\n",
    "    return f\"### {doc.metadata['title']}\\n\\nSummary: {doc.page_content}\\n\\nRelated\\n{related}\"[:max_length]\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(format_doc(doc) for doc in docs)\n",
    "\n",
    "@as_runnable\n",
    "async def survey_subjects(topic: str):\n",
    "    related_subjects = await expand_chain.ainvoke({\"topic\": topic})\n",
    "    retrieved_docs = await wikipedia_retriever.abatch(\n",
    "        related_subjects.topics, return_exceptions=True\n",
    "    )\n",
    "    all_docs = []\n",
    "    for docs in retrieved_docs:\n",
    "        if isinstance(docs, BaseException):\n",
    "            continue\n",
    "        all_docs.extend(docs)\n",
    "    formatted = format_docs(all_docs)\n",
    "    return await gen_perspectives_chain.ainvoke({\"examples\": formatted, \"topic\": topic})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p8/wg2_6tz10x111q372jxw6ghc0000gn/T/ipykernel_66443/35571063.py:2: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  perspectives.dict()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'editors': [{'affilation': 'Kazakh Linguistic Institute',\n",
       "   'name': 'Ayman Kairbekova',\n",
       "   'role': 'Linguist',\n",
       "   'description': 'Focuses on the linguistic properties of the Kazakh language, including grammatical structure, colloquialisms, and regional dialects. She will ensure that the generated content adheres to the rules of Kazakh syntax and vocabulary, and that it reflects cultural nuances.'},\n",
       "  {'affilation': 'OpenAI',\n",
       "   'name': 'Dr. Askar Jonbekov',\n",
       "   'role': 'AI Researcher',\n",
       "   'description': 'Works on applying large language models in multilingual contexts. His expertise lies in adapting LLMs for underrepresented languages like Kazakh. He will emphasize the methodology of fine-tuning existing LLMs to capture Kazakh language features.'},\n",
       "  {'affilation': 'University of Almaty',\n",
       "   'name': 'Bota Suleimenova',\n",
       "   'role': 'Computational Linguist',\n",
       "   'description': 'Her research specializes in developing language resources for Kazakh, such as corpora and lexical databases. She will contribute to the technical aspects of building an LLM by sourcing quality datasets and ensuring linguistic accuracy.'},\n",
       "  {'affilation': 'Kazakh Language Department of the Culture Ministry',\n",
       "   'name': 'Zhanar Nauryzbaeva',\n",
       "   'role': 'Cultural Advisor',\n",
       "   'description': \"Brings in knowledge about the cultural significance and historical context of the Kazakh language. She will advise on the importance of including cultural references and context in the LLM's training data.\"},\n",
       "  {'affilation': 'Nazarbayev University',\n",
       "   'name': 'Erbol Mukanov',\n",
       "   'role': 'Ethicist in AI',\n",
       "   'description': 'Focuses on the ethical implications of AI technologies, particularly around language representation. His role will be to ensure that the LLM respects and promotes Kazakh linguistic heritage and does not propagate biases or misrepresentations.'},\n",
       "  {'affilation': 'Freelance Content Creator',\n",
       "   'name': 'Aliya Doszhanova',\n",
       "   'role': 'User Experience Specialist',\n",
       "   'description': 'As a native Kazakh speaker with experience in content creation, she will provide insights into user expectations and practical applications of the LLM, ensuring that generated outputs are user-friendly and culturally appropriate.'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspectives = await survey_subjects.ainvoke(example_topic)\n",
    "perspectives.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expert Dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interview State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "def add_message(left, right):\n",
    "    if not isinstance(left, list):\n",
    "        left = [left]\n",
    "    if not isinstance(right, list):\n",
    "        right = [right]\n",
    "    return left + right\n",
    "\n",
    "def update_references(references, new_references):\n",
    "    if not references:\n",
    "        references = {}\n",
    "    references.update(new_references)\n",
    "    return references\n",
    "\n",
    "def update_editor(editor, new_editor):\n",
    "    # Can only set at the outset\n",
    "    if not editor:\n",
    "        return new_editor\n",
    "    return editor\n",
    "\n",
    "class InterviewState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_message]\n",
    "    references: Annotated[Optional[dict], update_references]\n",
    "    editor: Annotated[Optional[Editor], update_editor]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialog Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "gen_qn_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "    \"system\",\n",
    "            \"\"\"You are an experienced Wikipedia writer and want to edit a specific page. \\\n",
    "            Besides your identity as a Wikipedia writer, you have a specific focus when researching the topic. \\\n",
    "            Now, you are chatting with an expert to get information. Ask good questions to get more useful information.  \\\n",
    "            When you have no more questions to ask, say \"Thank you so much for your help!\" to end the conversation.\\\n",
    "            Please only ask one question at a time and don't ask what you have asked before.\\\n",
    "            Your questions should be related to the topic you want to write.\n",
    "            Be comprehensive and curious, gaining as much unique insight from the expert as possible.\\\n",
    "            Stay true to your specific perspective: {persona}\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def tag_with_name(ai_message: AIMessage, name: str):\n",
    "    valid_name = ''.join(c for c in name if c.isalnum() or c in ['_', '-'])\n",
    "    ai_message.name = valid_name\n",
    "    return ai_message\n",
    "\n",
    "def swap_roles(state: InterviewState, name: str):\n",
    "    converted = []\n",
    "    for message in state['messages']:\n",
    "        if isinstance(message, AIMessage) and message.name != name:\n",
    "            message = HumanMessage(**message.model_dump(exclude={\"type\"}))\n",
    "        converted.append(message)\n",
    "    return {\"messages\": converted}\n",
    "\n",
    "@as_runnable\n",
    "async def generate_question(state: InterviewState):\n",
    "    editor = state[\"editor\"]\n",
    "    gn_chain = (\n",
    "        RunnableLambda(swap_roles).bind(name=editor.name)\n",
    "        | gen_qn_prompt.partial(persona=editor.persona)\n",
    "        | fast_llm\n",
    "        | RunnableLambda(tag_with_name).bind(name=editor.name)\n",
    "    )\n",
    "    result = await gn_chain.ainvoke(state)\n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I’m actually focused on enhancing content related to the linguistic properties of the Kazakh language, including its grammatical structure and regional dialects. What specific aspects of Kazakh syntax or colloquialisms do you think are most important for a language model to understand in order to generate natural Kazakh text?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(f\"So you said you were writing an article on {example_topic}?\")\n",
    "]\n",
    "question = await generate_question.ainvoke(\n",
    "    {\n",
    "        \"editor\": perspectives.editors[0],\n",
    "        \"messages\": messages,\n",
    "    }\n",
    ")\n",
    "question[\"messages\"][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queries(BaseModel):\n",
    "    queries: List[str] = Field(\n",
    "        description=\"Comprehensive list of search engine queries to answer the user's questions.\",\n",
    "    )\n",
    "gen_queries_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful research assistant. Query the search engine to answer the user's questions.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "gen_queries_chain = gen_queries_prompt | ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\"\n",
    ").with_structured_output(Queries, include_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kazakh language grammatical structure',\n",
       " 'Kazakh syntax rules',\n",
       " 'Kazakh language regional dialects',\n",
       " 'important aspects of Kazakh syntax',\n",
       " 'colloquial expressions in Kazakh',\n",
       " 'Kazakh language morphological features',\n",
       " 'Kazakh sentence structure variations',\n",
       " 'Kazakh verb conjugation rules',\n",
       " 'Kazakh noun cases and usage',\n",
       " 'Kazakh language idiomatic expressions',\n",
       " 'differences between Kazakh dialects',\n",
       " 'Kazakh language punctuation rules',\n",
       " 'Kazakh prepositions and their usage',\n",
       " 'impact of regional dialects on Kazakh written language',\n",
       " 'language model training for Kazakh text generation']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = await gen_queries_chain.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "queries['parsed'].queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithCitations(BaseModel):\n",
    "    answer: str = Field(\n",
    "        description=\"Comprehensive answer to the user's question with citations.\",\n",
    "    )\n",
    "    cited_urls: List[str] = Field(\n",
    "        description=\"List of urls cited in the answer\",\n",
    "    )\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.answer}\\n\\nCitations:\\n\\n\" + \"\\n\".join(\n",
    "            f\"[{i+1}]: {url}\" for i, url in enumerate(self.cited_urls)\n",
    "        )\n",
    "gen_answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert who can use information effectively. You are chatting with a Wikipedia writer who wants\\\n",
    "                to write a Wikipedia page on the topic you know. You have gathered the related information and will now use the information to form a response.\\\n",
    "            Make your response as informative as possible and make sure every sentence is supported by the gathered information.\\\n",
    "Each response must be backed up by a citation from a reliable source, formatted as a footnote, reproducing the URLS after your response.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_answer_chain = gen_answer_prompt | fast_llm.with_structured_output(\n",
    "    AnswerWithCitations, include_raw=True\n",
    ").with_config(run_name=\"GenerateAnswer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "search_engine = DuckDuckGoSearchAPIWrapper()\n",
    "\n",
    "@tool\n",
    "async def search_engine(query: str) -> str:\n",
    "    \"\"\"Search engine to the internet.\"\"\"\n",
    "    results = DuckDuckGoSearchAPIWrapper()._ddgs_text(query)\n",
    "    return [{\"content\": r[\"body\"], \"url\": r['href']} for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "async def gen_answer(\n",
    "        state: InterviewState,\n",
    "        config: Optional[RunnableConfig] = None,\n",
    "        name: str = \"Subject_Matter_Expert\",\n",
    "        max_str_len: int = 15000,\n",
    "):\n",
    "    valid_name = ''.join(c for c in name if c.isalnum() or c in ['_', '-'])\n",
    "    swapped_state = swap_roles(state, valid_name) # Convert all other AI messages\n",
    "    queries = await gen_queries_chain.ainvoke(swapped_state)\n",
    "    query_results = await search_engine.abatch(\n",
    "        queries['parsed'].queries, config, return_exceptions=True\n",
    "    )\n",
    "    successfull_results = [\n",
    "        res for res in query_results if not isinstance(res, Exception)\n",
    "    ]\n",
    "    all_query_results = {\n",
    "        res['url']: res['content'] for results in successfull_results for res in results\n",
    "    }\n",
    "\n",
    "    dumped = json.dumps(all_query_results)[:max_str_len]\n",
    "    ai_message: AIMessage = queries[\"raw\"]\n",
    "    \n",
    "    # Check if tool_calls is not empty\n",
    "    if ai_message.tool_calls:\n",
    "        tool_call = ai_message.tool_calls[0]\n",
    "        tool_id = tool_call[\"id\"]\n",
    "        tool_message = ToolMessage(tool_call_id=tool_id, content=dumped)\n",
    "        swapped_state[\"messages\"].extend([ai_message, tool_message])\n",
    "    else:\n",
    "        # Handle the case where tool_calls is empty\n",
    "        print(\"Warning: No tool calls found in the AI message.\")\n",
    "        return {\"messages\": [ai_message], \"references\": {}}\n",
    "\n",
    "    # Only update the shared state with the final answer to avoid\n",
    "    # polluting the dialogue history with intermediate messages\n",
    "    generated = await gen_answer_chain.ainvoke(swapped_state)\n",
    "    cited_urls = set(generated[\"parsed\"].cited_urls)\n",
    "    # Save the retrieved information to the shared state for future reference\n",
    "    cited_references = {k: v for k, v in all_query_results.items() if k in cited_urls}\n",
    "    formatted_message = AIMessage(name=name, content=generated[\"parsed\"].as_str)\n",
    "    return {\"messages\": [formatted_message], \"references\": cited_references}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No tool calls found in the AI message.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"queries\":[\"Kazakh language grammatical structure\",\"Kazakh syntax rules\",\"Kazakh language regional dialects\",\"Important colloquialisms in Kazakh\",\"Kazakh sentence structure\",\"Kazakh morphology and syntax\",\"Common phrases in Kazakh dialects\",\"Kazakh language phonetics and phonology\",\"Differences between Kazakh dialects\",\"Natural language processing in Kazakh\",\"Kazakh verb conjugation patterns\",\"Kazakh noun cases\",\"Kazakh pronouns and their usage\",\"Kazakh language idiomatic expressions\",\"Contextual usage of Kazakh expressions\",\"Language model training for Kazakh\"]}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_answer  = await gen_answer(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "example_answer[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Interview Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_turns = 5\n",
    "from langgraph.pregel import RetryPolicy\n",
    "\n",
    "def route_messages(state: InterviewState, name: str = \"Subject_Matter_Expert\"):\n",
    "    messages = state[\"messages\"]\n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "    if num_responses >= max_num_turns:\n",
    "        return END\n",
    "    last_question = messages[-2]\n",
    "    if last_question.content.endswith(\"Thank you so much for your help!\"):\n",
    "        return END\n",
    "    return \"ask_question\"\n",
    "\n",
    "builder = StateGraph(InterviewState)\n",
    "builder.add_node(\"ask_question\", generate_question, retry=RetryPolicy(max_attempts=5))\n",
    "builder.add_node(\"answer_question\", gen_answer, retry=RetryPolicy(max_attempts=5))\n",
    "builder.add_conditional_edges(\"answer_question\", route_messages)\n",
    "builder.add_edge(\"ask_question\", \"answer_question\")\n",
    "\n",
    "\n",
    "builder.add_edge(START, \"ask_question\")\n",
    "interview_graph = builder.compile(checkpointer=False).with_config(run_name=\"Conduct Interviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(interview_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_step = None\n",
    "initial_state = {\n",
    "    \"editor\": perspectives.editors[0],\n",
    "    \"messages\": [\n",
    "        AIMessage(\n",
    "            content=f\"So you said you were writing an article on {example_topic}?\",\n",
    "            name=\"Subject_Matter_Expert\",\n",
    "        )\n",
    "    ],\n",
    "\n",
    "}\n",
    "async for step in interview_graph.astream(initial_state):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"--\", str(step[name]['messages'])[:300])\n",
    "final_step = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = next(iter(final_step.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a Wikipedia writer. You have gathered information from experts and search engines. \\\n",
    "                Now, you are refining the outline of the Wikipedia page. \\\n",
    "                You need to make sure that the outline is comprehensive and specific. \\\n",
    "                Topic you are writing about: {topic} \\\n",
    "                Old outline: {old_outline}\"\"\",\n",
    "        ),\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
